{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b\n",
       "2  3.0  6.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"a\": [np.nan, 2, 3], \"b\": [4, np.inf, 6]}\n",
    ")\n",
    "df = df[df.map(np.isfinite).sum(axis=1) == df.shape[1]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "started create today at Mon 07 Apr 2025, 02:57PM\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './SHARADAR_TICKERS.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# read tickers and find ones to keep\u001b[39;00m\n\u001b[0;32m     15\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTICKERS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./SHARADAR_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zipObj:\n\u001b[0;32m     17\u001b[0m     name \u001b[38;5;241m=\u001b[39m zipObj\u001b[38;5;241m.\u001b[39mnamelist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     18\u001b[0m     zipObj\u001b[38;5;241m.\u001b[39mextractall()\n",
      "File \u001b[1;32mc:\\Users\\kerry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1362\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1363\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1364\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './SHARADAR_TICKERS.zip'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from sqlalchemy import create_engine\n",
    "import pymssql\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np \n",
    "from pandas_datareader import DataReader as pdr\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime\n",
    "\n",
    "n1 = datetime.now()\n",
    "print(f\"\\nstarted create today at {n1.strftime('%a %d %b %Y, %I:%M%p')}\")\n",
    "\n",
    "# read tickers and find ones to keep\n",
    "table = \"TICKERS\"\n",
    "with ZipFile('./SHARADAR_'+table+'.zip', 'r') as zipObj:\n",
    "    name = zipObj.namelist()[0]\n",
    "    zipObj.extractall()\n",
    "tickers = pd.read_csv(name, low_memory=False)\n",
    "tickers = tickers[tickers.table==\"SF1\"]\n",
    "tickers = tickers[\n",
    "    (tickers.exchange.isin((\"NYSE\", \"NASDAQ\", \"NYSEMKT\"))) & \n",
    "    (tickers.category.isin([\"Domestic Common Stock\", \"Domestic Common Stock Primary Class\"]))\n",
    "]\n",
    "tickers = tickers.drop(columns=[\"table\", \"category\"])\n",
    "tickers_keep = tickers.ticker.to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymssql\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from pandas_datareader import DataReader as pdr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"\\n\", datetime.today(), \"\\n\")\n",
    "\n",
    "server = 'fs.rice.edu'\n",
    "database = 'stocks'\n",
    "username = 'keb7'\n",
    "password = \"penguinSQL1\"\n",
    "\n",
    "string = \"mssql+pymssql://\" + username + \":\" + password + \"@\" + server + \"/\" + database \n",
    "conn = create_engine(string).connect()\n",
    "\n",
    "\n",
    "quarterly = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select datekey, reportperiod, ticker, netinc, equity, assets\n",
    "    from sf1\n",
    "    where dimension='ARQ' and equity>0 and assets>0\n",
    "    order by ticker, datekey\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "quarterly = quarterly.dropna()\n",
    "\n",
    "# calculate roeq\n",
    "\n",
    "quarterly[\"assetslag\"] = quarterly.groupby(\"ticker\").assets.shift()\n",
    "quarterly[\"equitylag\"] = quarterly.groupby(\"ticker\").equity.shift()\n",
    "quarterly[\"roeq\"] = quarterly.netinc / quarterly.equitylag\n",
    "quarterly[\"roaq\"] = quarterly.netinc / quarterly.assetslag\n",
    "\n",
    "# save last report for each firm\n",
    "quarterly = quarterly.groupby(\"ticker\").last()\n",
    "quarterly = quarterly[quarterly.datekey.astype(str)>=\"2022-06-01\"]\n",
    "\n",
    "# drop variables other than roeq and ticker (ticker=index)\n",
    "quarterly = quarterly[[\"roeq\", \"roaq\"]]\n",
    "print(\"finished quarterly\")\n",
    "\n",
    "annual = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select datekey, reportperiod, ticker, netinc, ncfo, assets, assetsavg, equity, inventory\n",
    "    equityavg, revenue, cor, liabilities, marketcap, sgna, intexp, sharesbas, currentratio, roic,\n",
    "    ebit, opinc, cashneq\n",
    "    from sf1\n",
    "    where dimension='ARY' and assets>0 and equity>0\n",
    "    order by ticker, datekey\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "annual = annual.dropna(subset=[\"ticker\"])\n",
    "annual = annual.rename(columns={\"currentratio\": \"currat\"})\n",
    "\n",
    "# calculate predictors\n",
    "\n",
    "annual[\"equitylag\"] = annual.groupby(\"ticker\").equity.shift()\n",
    "annual[\"assetslag\"] = annual.groupby(\"ticker\").assets.shift()\n",
    "annual[\"acc\"] = (annual.netinc - annual.ncfo) / annual.assetsavg\n",
    "annual[\"agr\"] = annual.groupby(\"ticker\").assets.pct_change()\n",
    "annual[\"bm\"] = annual.equity / annual.marketcap\n",
    "annual[\"ep\"] = annual.netinc / annual.marketcap\n",
    "annual[\"gma\"] = (annual.revenue-annual.cor) / annual.assetslag\n",
    "annual[\"lev\"] = annual.liabilities / annual.marketcap\n",
    "annual[\"operprof\"] = (annual.revenue-annual.cor-annual.sgna-annual.intexp) / annual.equitylag\n",
    "annual[\"saleinv\"] = annual.revenue / annual.revenue\n",
    "annual[\"roic\"] = (annual.ebit - (annual.netinc-annual.opinc)) / (annual.assets + annual.equity - annual.cashneq)\n",
    "\n",
    "\n",
    "# save last report for each firm\n",
    "\n",
    "annual = annual.groupby(\"ticker\").last()\n",
    "annual = annual[annual.datekey.astype(str) >= \"2021-09-01\"]\n",
    "\n",
    "# drop variables other than predictors and ticker (ticker=index)\n",
    "\n",
    "annual = annual[[\"acc\", \"agr\", \"bm\", \"ep\", \"gma\", \"lev\", \"operprof\", \"currat\", \"saleinv\", \"roic\"]]\n",
    "print(\"finished annual\")\n",
    "\n",
    "prices = pd.read_csv(\"sep.csv\")\n",
    "prices = prices[prices.date>=\"2024-04-01\"]\n",
    "prices = prices.sort_values(by=[\"ticker\", \"date\"])\n",
    "prices = prices.groupby(\"ticker\").last()\n",
    "    \"\"\"\n",
    "    select ticker, date, closeadj, close_, volume\n",
    "    from sep\n",
    "    where date>='2019-11-02'\n",
    "    order by ticker, date\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "prices = prices.dropna()\n",
    "prices[\"date\"] = pd.to_datetime(prices.date)\n",
    "\n",
    "rets = prices.set_index([\"ticker\", \"date\"]).groupby(\"ticker\").closeadj.pct_change()\n",
    "retvol = rets.groupby(\"ticker\").apply(lambda d:d.iloc[-21:].std())\n",
    "retvol.name = \"retvol\"\n",
    "\n",
    "\n",
    "# define year and week for each row\n",
    "\n",
    "prices[\"year\"] = prices.date.apply(lambda x: x.isocalendar()[0])\n",
    "prices[\"week\"] = prices.date.apply(lambda x: x.isocalendar()[1])\n",
    "print(\"finished prices\")\n",
    "\n",
    "# find last day of each week\n",
    "\n",
    "week = prices.groupby([\"year\", \"week\"]).date.max()\n",
    "week.name = \"weekdate\"\n",
    "\n",
    "# keep only last day of each week\n",
    "\n",
    "prices = prices.merge(week, on=[\"year\", \"week\"])\n",
    "weekly = prices.groupby([\"ticker\", \"weekdate\"]).last()\n",
    "print(\"finished weekly\")\n",
    "\n",
    "# compute weekly returns\n",
    "\n",
    "returns = weekly.groupby(\"ticker\").closeadj.pct_change()\n",
    "returns = returns.reset_index()\n",
    "returns.columns = [\"ticker\", \"date\", \"ret\"]\n",
    "\n",
    "# get risk-free rate and market excess return from Kenneth French's data library\n",
    "\n",
    "factors = pdr(\"F-F_Research_Data_Factors_weekly\", \"famafrench\", start=2019)[0] / 100\n",
    "\n",
    "# merge into weekly returns and compute weekly excess returns\n",
    "\n",
    "returns = returns.merge(factors, left_on=\"date\", right_on=\"Date\")\n",
    "returns[\"ret\"] = returns.ret - returns.RF\n",
    "returns[\"mkt\"] = returns[\"Mkt-RF\"]\n",
    "\n",
    "# keep three years of returns\n",
    "\n",
    "d = datetime.today() - timedelta(days=365*3)\n",
    "d = str(d).split()[0]\n",
    "returns = returns[returns.date >= d].dropna()\n",
    "print(\"finished returns\")\n",
    "\n",
    "# run regressions to compute beta and idiosyncratic volatility for each stock\n",
    "\n",
    "def regr(d):\n",
    "    if d.shape[0] < 52:\n",
    "        return pd.Series(np.nan, index=[\"beta\", \"idiovol\"])\n",
    "    else:\n",
    "        model = smf.ols(\"ret ~ mkt\", data=d)\n",
    "        result = model.fit()\n",
    "        beta = result.params[\"mkt\"]\n",
    "        idiovol = np.sqrt(result.mse_resid)\n",
    "        return pd.Series([beta, idiovol], index=[\"beta\", \"idiovol\"])\n",
    "\n",
    "regression = returns.groupby(\"ticker\").apply(regr)\n",
    "print(\"finished regression\")\n",
    "\n",
    "# keep only last year+ of data\n",
    "\n",
    "d = datetime.today() - timedelta(days=375)\n",
    "d = str(d).split()[0]\n",
    "prices = prices[prices.date>=d]\n",
    "\n",
    "# get adjusted prices 1 year + 1 day ago, 1 month + 1 day ago, and 1 day ago\n",
    "\n",
    "prices[\"price12m\"] = prices.groupby(\"ticker\").closeadj.shift(253)\n",
    "prices[\"price1m\"] = prices.groupby(\"ticker\").closeadj.shift(22)\n",
    "prices[\"price1d\"] = prices.groupby(\"ticker\").closeadj.shift(1)\n",
    "\n",
    "# return over last 12 months excluding most recent month\n",
    "\n",
    "prices[\"mom12m\"] = prices.price1m / prices.price12m - 1\n",
    "\n",
    "# return over most recent month\n",
    "\n",
    "prices[\"mom1m\"] = prices.price1d / prices.price1m - 1\n",
    "\n",
    "# keep only last momentum for each stock and ticker (ticker=index)\n",
    "\n",
    "momentum = prices[[\"ticker\", \"date\", \"mom12m\", \"mom1m\"]]\n",
    "momentum = momentum[momentum.date==momentum.date.max()]\n",
    "momentum = momentum.set_index(\"ticker\")[[\"mom12m\", \"mom1m\"]]\n",
    "print(\"finished momentum\")\n",
    "\n",
    "prices = prices[prices.date==prices.date.max()][[\"ticker\", \"close_\"]]\n",
    "prices = prices.set_index(\"ticker\")\n",
    "prices.columns = [\"price\"]\n",
    "\n",
    "mktcap = pd.read_sql(\n",
    "    \"\"\" \n",
    "    select date, ticker, marketcap\n",
    "    from daily\n",
    "    where date>='2022-12-06'\n",
    "    order by ticker, date\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "mktcap = mktcap.dropna()\n",
    "mktcap = mktcap.groupby(\"ticker\").last()\n",
    "mktcap[\"mve\"] = np.log(mktcap.marketcap)\n",
    "print(\"finished mktcap\")\n",
    "\n",
    "df = pd.DataFrame(quarterly).join(annual, how=\"outer\")\n",
    "for d in [regression, momentum, prices, mktcap, retvol]:\n",
    "    df = df.join(d, how=\"outer\")\n",
    "# df = pd.concat((quarterly, annual, regression, momentum, prices, mktcap, retvol), axis=1)\n",
    "df = df[df.price > 5]\n",
    "floats = [x for x in df.columns.to_list() if x!=\"date\"]\n",
    "\n",
    "columns = \"ticker, name, exchange, siccode as siccd, sicsector, sicindustry, famaindustry, sector, industry, scalemarketcap, scalerevenue\"\n",
    "string = \"select \" + columns + \" from tickers\"\n",
    "\n",
    "ticks = pd.read_sql(string, conn)\n",
    "ticks = ticks.set_index(\"ticker\")\n",
    "df = df.merge(ticks, left_index=True, right_index=True, how=\"outer\")\n",
    "df = df.reset_index()\n",
    "\n",
    "ints = [\"siccd\"]\n",
    "dates = [\"date\"]\n",
    "other = [x for x in df.columns if x not in ints+floats+dates]\n",
    "\n",
    "string = \"create table today (\" \n",
    "string += \" int, \".join(ints) + \" int, \"\n",
    "string += \" date, \".join(dates) + \" date, \"\n",
    "string += \" float, \".join(floats) + \" float, \"\n",
    "string += \" varchar(max), \".join(other) + \" varchar(max)) \"\n",
    "\n",
    "df = df[ints+dates+floats+other]\n",
    "conn.execute(\"drop table if exists today\")\n",
    "conn.execute(string)\n",
    "df.to_sql('today', conn, index=False, if_exists='append')\n",
    "print(\"finished today\")\n",
    "\n",
    "string = \"create table ghz (\" \n",
    "string += \" int, \".join(ints) + \" int, \"\n",
    "string += \" date, \".join(dates) + \" date, \"\n",
    "string += \" float, \".join(floats) + \" float, \"\n",
    "string += \" varchar(max), \".join(other) + \" varchar(max)) \"\n",
    "\n",
    "df = df[ints+dates+floats+other]\n",
    "conn.execute(\"drop table if exists ghz\")\n",
    "conn.execute(string)\n",
    "df.to_sql('ghz', conn, index=False, if_exists='append')\n",
    "print(\"finished ghz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymssql\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from pandas_datareader import DataReader as pdr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"\\n\", datetime.today(), \"\\n\")\n",
    "\n",
    "server = 'fs.rice.edu'\n",
    "database = 'stocks'\n",
    "username = 'keb7'\n",
    "password = \"penguinSQL1\"\n",
    "\n",
    "string = \"mssql+pymssql://\" + username + \":\" + password + \"@\" + server + \"/\" + database \n",
    "conn = create_engine(string).connect()\n",
    "\n",
    "\n",
    "quarterly = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select datekey, reportperiod, ticker, netinc, equity, assets\n",
    "    from sf1\n",
    "    where dimension='ARQ' and equity>0 and assets>0\n",
    "    order by ticker, datekey\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "quarterly = quarterly.dropna()\n",
    "\n",
    "# calculate roeq\n",
    "\n",
    "quarterly[\"assetslag\"] = quarterly.groupby(\"ticker\").assets.shift()\n",
    "quarterly[\"equitylag\"] = quarterly.groupby(\"ticker\").equity.shift()\n",
    "quarterly[\"roeq\"] = quarterly.netinc / quarterly.equitylag\n",
    "quarterly[\"roaq\"] = quarterly.netinc / quarterly.assetslag\n",
    "\n",
    "# save last report for each firm\n",
    "quarterly = quarterly.groupby(\"ticker\").last()\n",
    "quarterly = quarterly[quarterly.datekey.astype(str)>=\"2022-06-01\"]\n",
    "\n",
    "# drop variables other than roeq and ticker (ticker=index)\n",
    "quarterly = quarterly[[\"roeq\", \"roaq\"]]\n",
    "print(\"finished quarterly\")\n",
    "\n",
    "annual = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select datekey, reportperiod, ticker, netinc, ncfo, assets, assetsavg, equity, inventory\n",
    "    equityavg, revenue, cor, liabilities, marketcap, sgna, intexp, sharesbas, currentratio, roic,\n",
    "    ebit, opinc, cashneq\n",
    "    from sf1\n",
    "    where dimension='ARY' and assets>0 and equity>0\n",
    "    order by ticker, datekey\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "annual = annual.dropna(subset=[\"ticker\"])\n",
    "annual = annual.rename(columns={\"currentratio\": \"currat\"})\n",
    "\n",
    "# calculate predictors\n",
    "\n",
    "annual[\"equitylag\"] = annual.groupby(\"ticker\").equity.shift()\n",
    "annual[\"assetslag\"] = annual.groupby(\"ticker\").assets.shift()\n",
    "annual[\"acc\"] = (annual.netinc - annual.ncfo) / annual.assetsavg\n",
    "annual[\"agr\"] = annual.groupby(\"ticker\").assets.pct_change()\n",
    "annual[\"bm\"] = annual.equity / annual.marketcap\n",
    "annual[\"ep\"] = annual.netinc / annual.marketcap\n",
    "annual[\"gma\"] = (annual.revenue-annual.cor) / annual.assetslag\n",
    "annual[\"lev\"] = annual.liabilities / annual.marketcap\n",
    "annual[\"operprof\"] = (annual.revenue-annual.cor-annual.sgna-annual.intexp) / annual.equitylag\n",
    "annual[\"saleinv\"] = annual.revenue / annual.revenue\n",
    "annual[\"roic\"] = (annual.ebit - (annual.netinc-annual.opinc)) / (annual.assets + annual.equity - annual.cashneq)\n",
    "\n",
    "\n",
    "# save last report for each firm\n",
    "\n",
    "annual = annual.groupby(\"ticker\").last()\n",
    "annual = annual[annual.datekey.astype(str) >= \"2021-09-01\"]\n",
    "\n",
    "# drop variables other than predictors and ticker (ticker=index)\n",
    "\n",
    "annual = annual[[\"acc\", \"agr\", \"bm\", \"ep\", \"gma\", \"lev\", \"operprof\", \"currat\", \"saleinv\", \"roic\"]]\n",
    "print(\"finished annual\")\n",
    "\n",
    "prices = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select ticker, date, closeadj, close_, volume\n",
    "    from sep\n",
    "    where date>='2019-11-02'\n",
    "    order by ticker, date\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "prices = prices.dropna()\n",
    "prices[\"date\"] = pd.to_datetime(prices.date)\n",
    "\n",
    "rets = prices.set_index([\"ticker\", \"date\"]).groupby(\"ticker\").closeadj.pct_change()\n",
    "retvol = rets.groupby(\"ticker\").apply(lambda d:d.iloc[-21:].std())\n",
    "retvol.name = \"retvol\"\n",
    "\n",
    "\n",
    "# define year and week for each row\n",
    "\n",
    "prices[\"year\"] = prices.date.apply(lambda x: x.isocalendar()[0])\n",
    "prices[\"week\"] = prices.date.apply(lambda x: x.isocalendar()[1])\n",
    "print(\"finished prices\")\n",
    "\n",
    "# find last day of each week\n",
    "\n",
    "week = prices.groupby([\"year\", \"week\"]).date.max()\n",
    "week.name = \"weekdate\"\n",
    "\n",
    "# keep only last day of each week\n",
    "\n",
    "prices = prices.merge(week, on=[\"year\", \"week\"])\n",
    "weekly = prices.groupby([\"ticker\", \"weekdate\"]).last()\n",
    "print(\"finished weekly\")\n",
    "\n",
    "# compute weekly returns\n",
    "\n",
    "returns = weekly.groupby(\"ticker\").closeadj.pct_change()\n",
    "returns = returns.reset_index()\n",
    "returns.columns = [\"ticker\", \"date\", \"ret\"]\n",
    "\n",
    "# get risk-free rate and market excess return from Kenneth French's data library\n",
    "\n",
    "factors = pdr(\"F-F_Research_Data_Factors_weekly\", \"famafrench\", start=2019)[0] / 100\n",
    "\n",
    "# merge into weekly returns and compute weekly excess returns\n",
    "\n",
    "returns = returns.merge(factors, left_on=\"date\", right_on=\"Date\")\n",
    "returns[\"ret\"] = returns.ret - returns.RF\n",
    "returns[\"mkt\"] = returns[\"Mkt-RF\"]\n",
    "\n",
    "# keep three years of returns\n",
    "\n",
    "d = datetime.today() - timedelta(days=365*3)\n",
    "d = str(d).split()[0]\n",
    "returns = returns[returns.date >= d].dropna()\n",
    "print(\"finished returns\")\n",
    "\n",
    "# run regressions to compute beta and idiosyncratic volatility for each stock\n",
    "\n",
    "def regr(d):\n",
    "    if d.shape[0] < 52:\n",
    "        return pd.Series(np.nan, index=[\"beta\", \"idiovol\"])\n",
    "    else:\n",
    "        model = smf.ols(\"ret ~ mkt\", data=d)\n",
    "        result = model.fit()\n",
    "        beta = result.params[\"mkt\"]\n",
    "        idiovol = np.sqrt(result.mse_resid)\n",
    "        return pd.Series([beta, idiovol], index=[\"beta\", \"idiovol\"])\n",
    "\n",
    "regression = returns.groupby(\"ticker\").apply(regr)\n",
    "print(\"finished regression\")\n",
    "\n",
    "# keep only last year+ of data\n",
    "\n",
    "d = datetime.today() - timedelta(days=375)\n",
    "d = str(d).split()[0]\n",
    "prices = prices[prices.date>=d]\n",
    "\n",
    "# get adjusted prices 1 year + 1 day ago, 1 month + 1 day ago, and 1 day ago\n",
    "\n",
    "prices[\"price12m\"] = prices.groupby(\"ticker\").closeadj.shift(253)\n",
    "prices[\"price1m\"] = prices.groupby(\"ticker\").closeadj.shift(22)\n",
    "prices[\"price1d\"] = prices.groupby(\"ticker\").closeadj.shift(1)\n",
    "\n",
    "# return over last 12 months excluding most recent month\n",
    "\n",
    "prices[\"mom12m\"] = prices.price1m / prices.price12m - 1\n",
    "\n",
    "# return over most recent month\n",
    "\n",
    "prices[\"mom1m\"] = prices.price1d / prices.price1m - 1\n",
    "\n",
    "# keep only last momentum for each stock and ticker (ticker=index)\n",
    "\n",
    "momentum = prices[[\"ticker\", \"date\", \"mom12m\", \"mom1m\"]]\n",
    "momentum = momentum[momentum.date==momentum.date.max()]\n",
    "momentum = momentum.set_index(\"ticker\")[[\"mom12m\", \"mom1m\"]]\n",
    "print(\"finished momentum\")\n",
    "\n",
    "prices = prices[prices.date==prices.date.max()][[\"ticker\", \"close_\"]]\n",
    "prices = prices.set_index(\"ticker\")\n",
    "prices.columns = [\"price\"]\n",
    "\n",
    "mktcap = pd.read_sql(\n",
    "    \"\"\" \n",
    "    select date, ticker, marketcap\n",
    "    from daily\n",
    "    where date>='2022-12-06'\n",
    "    order by ticker, date\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "mktcap = mktcap.dropna()\n",
    "mktcap = mktcap.groupby(\"ticker\").last()\n",
    "mktcap[\"mve\"] = np.log(mktcap.marketcap)\n",
    "print(\"finished mktcap\")\n",
    "\n",
    "df = pd.DataFrame(quarterly).join(annual, how=\"outer\")\n",
    "for d in [regression, momentum, prices, mktcap, retvol]:\n",
    "    df = df.join(d, how=\"outer\")\n",
    "# df = pd.concat((quarterly, annual, regression, momentum, prices, mktcap, retvol), axis=1)\n",
    "df = df[df.price > 5]\n",
    "floats = [x for x in df.columns.to_list() if x!=\"date\"]\n",
    "\n",
    "columns = \"ticker, name, exchange, siccode as siccd, sicsector, sicindustry, famaindustry, sector, industry, scalemarketcap, scalerevenue\"\n",
    "string = \"select \" + columns + \" from tickers\"\n",
    "\n",
    "ticks = pd.read_sql(string, conn)\n",
    "ticks = ticks.set_index(\"ticker\")\n",
    "df = df.merge(ticks, left_index=True, right_index=True, how=\"outer\")\n",
    "df = df.reset_index()\n",
    "\n",
    "ints = [\"siccd\"]\n",
    "dates = [\"date\"]\n",
    "other = [x for x in df.columns if x not in ints+floats+dates]\n",
    "\n",
    "string = \"create table today (\" \n",
    "string += \" int, \".join(ints) + \" int, \"\n",
    "string += \" date, \".join(dates) + \" date, \"\n",
    "string += \" float, \".join(floats) + \" float, \"\n",
    "string += \" varchar(max), \".join(other) + \" varchar(max)) \"\n",
    "\n",
    "df = df[ints+dates+floats+other]\n",
    "conn.execute(\"drop table if exists today\")\n",
    "conn.execute(string)\n",
    "df.to_sql('today', conn, index=False, if_exists='append')\n",
    "print(\"finished today\")\n",
    "\n",
    "string = \"create table ghz (\" \n",
    "string += \" int, \".join(ints) + \" int, \"\n",
    "string += \" date, \".join(dates) + \" date, \"\n",
    "string += \" float, \".join(floats) + \" float, \"\n",
    "string += \" varchar(max), \".join(other) + \" varchar(max)) \"\n",
    "\n",
    "df = df[ints+dates+floats+other]\n",
    "conn.execute(\"drop table if exists ghz\")\n",
    "conn.execute(string)\n",
    "df.to_sql('ghz', conn, index=False, if_exists='append')\n",
    "print(\"finished ghz\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
